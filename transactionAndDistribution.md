# Transaction isolation level
   ## 1.脏读：事务一读到事务二更新但未提交的数据 (读的是个“中间脏数据”)，事务二再回滚rollback还原到原数据.
   ## 2.不可重复读：事务一在事务二更新前读到一次数据，事务二更新提交后，事务一再次读，读到的新数据和刚开始的数据不一致.(前后数据不一致)
   ## 3.幻读：事务一刚开始读到N1条数据，事务二插入N2条提交若干数据，事务一再查得到N1+N2条.(前后条数不一致)
   
   解决：脏读、不可重复读都是多个事务对同一行数据又读又写 更新时发生的，加行锁 锁住那一行，只有一个事务可以操作
         幻读发生于整个表，对表插入多条数据，加表锁 锁住整个表，只有一个事务操作这个表.        可以加版本号???---->版本号是采用乐观锁
         
         
 # 事务的四大特性（ACID）  命令：begin   commit   rollback .     利用日志undo log保存原数据用来回滚， redo log进行提交用来持久化
      
        1. 原子性：一个事务的所有操作要么都成功，要么都失败. 失败rollback，成功commit  （转钱和收钱两步操作要么都成功，要么都失败）
        2. 一致性 ：从一个一致性状态转向另一个一致性状态                              （转钱前的总钱数和转钱后的总钱数要一样）
        3. 隔离性：事务间相互不干扰                                                 （你转钱和别人转钱没有干扰）
        4. 持久性：对数据的改变是恒久的                                              （转钱成功后就不能改变了，转款成功后无法退款）
   
   
  ###  2020/4/28 __   23:21     ↓↓↓
 # 分布式事务（一个大操作分布在不同的机器节点上，不是单体）：如微服务中   支付扣款-->生成订单-->库存减少  为一组操作（原子性）
 ##   1.解决：
         1.2PC： （“老大”让“众小弟”做事，“众小弟”全部同意，则开始各自的“任务”）  ----------要全票通过
            第一阶段 事务协调者向所有参与者发送prepare请求，接到Prepare请求之后，每一个参与者节点会各自执行与事务有关的数据更新，
                      写入Undo Log和Redo Log。如果参与者执行成功，暂时不提交事务，而是向事务协调节点返回“完成”消息。
            第二阶段 如果事务协调节点在之前所收到都是正向返回，那么它将会向所有事务参与者发出Commit请求。事务参与者节点会各自进行
               本地的事务提交，并释放锁资源。当本地事务完成提交后，将会向事务协调者返回“完成”消息。
 
          2.本地消息表：
                 发送方自己存一个本地消息表，把“大操作”存在本地消息表中  放入同一个事务(依靠数据库本地事务保证一致性）
                 定时任务去轮询这个本地事务表，没有发送的消息，扔给接收方服务器，叫它进行相应操作，到达接收方服务器，
             这时得先写入这个服务器的事务表，然后进行操作，操作成功后，更新事务表中的状态。
                 接收服务器通过定时任务扫描消息表或者直接通知发送方服务器，发送方服务器在本地消息表进行状态更新。
                
                
      另一种解释：
                消息表怎么创建呢？这个表应该包括这些字段： id, biz_id, biz_type, msg, msg_result, 
                msg_desc,atime,try_count。分别表示uuid，业务id，业务类型，消息内容，消息结果（成功或失败），
                消息描述，创建时间，重试次数， 其中biz_id，msg_desc字段是可选的。
                
             具体怎么做呢？
      ★★★       
     消息生产方（也就是发起方），需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，
     也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。

     消息消费方（也就是发起方的依赖方），需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，
     表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。

               生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，
               这种方案还是非常实用的。
               
               
               
               
     打比方：
           你妈给你10块钱去商店买酱油，结果店里酱油卖光了，你空手回来把10块钱交还给你妈。（买酱油失败，钱要回退回来）跑腿的你就是个中间的 MQ...
        当你回家没有给你妈酱油，你妈记得她给了你十块钱，会要回钱...
                
# 分布式ID生成（ID不能相同）
 1. 依靠主键自增：    缺点（每张表要记住上一张表的最后那行的id值）
 2. UUID             缺点（没意义的随机字符串，无序，查找慢）
 3. 雪花算法snowflake   ：  缺点（系统时间要一致，不然导致41位那个时间戳相同，可能导致相同）
 
        由64bit组成：第一位是0，代表正数 ； 再41位是时间戳毫秒；再5位机房id；再5位机器id；最后12位序列号， 每个节点每毫秒产生4096个ID序号
        既64 = 1 + 41 + 5 + 5 + 12
        
        
# 分布式锁
 1.利用数据库：不同节点都到一个数据库插入唯一主键，只有一个插入成功
 2.利用Redis：setnx 设置唯一的内存键，也只有一个可以成功
 3.利用zookeeper：创建临时节点，只有一个成功；创建有序节点，根据序号来依次执行
